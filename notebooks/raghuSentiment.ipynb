{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TEST TRANSCRIPTS: /var/users/raghavendra/CSAT_scripts/transcripts_mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "python_path = \"/mnt/NFS.cltlabnas1vg0/users/marke/anaconda3/bin/python\"\n",
    "exec_path='/mnt/NFS.cltlabnas1vg0/users/raghavendra/Github_version/evaluate_CV_v2_FUSE_CNNwithAF.py'\n",
    "arch_file='/mnt/NFS.cltlabnas1vg0/users/raghavendra/Github_version/best_result/run_1model_SPOKEN_Siamese.yaml'\n",
    "model_path='/mnt/NFS.cltlabnas1vg0/users/raghavendra/Github_version/best_result/run_1SPOKEN_Siamese_3.0_foldno_1_48-0.72.hdf5'\n",
    "\n",
    "#data_dir='/mnt/NFS.cltlabnas1vg0/users/raghavendra/Github_version/data_CV'\n",
    "data_dir = '/mnt/NFS.cltlabnas1vg0/users/marke/data/raghuTest/data'\n",
    "\n",
    "out_dir='/mnt/NFS.cltlabnas1vg0/users/marke/data/raghuTest'\n",
    "weight='3'\n",
    "suffix='fold_1'\n",
    "layer_indices='1,2' \n",
    "AF_data_path='/mnt/NFS.cltlabnas1vg0/users/raghavendra/Github_version/AF_data.h5'\n",
    "new_transcripts='1' \n",
    "\n",
    "#transcripts_dir=''\n",
    "transcripts_dir = '/mnt/NFS.cltlabnas1vg0/users/marke/data/raghuTest/transcripts/'\n",
    "\n",
    "post_string='test'\n",
    "fold_no='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "subprocess_list = [python_path, \n",
    "                   exec_path,\n",
    "                   arch_file,\n",
    "                   model_path, \n",
    "                   data_dir, \n",
    "                   out_dir, \n",
    "                   weight, \n",
    "                   suffix,\n",
    "                   layer_indices,\n",
    "                   AF_data_path,\n",
    "                   \"-n\",\n",
    "                   new_transcripts, \n",
    "                   \"-tr_dir\",\n",
    "                   transcripts_dir, \n",
    "                   \"-p\",\n",
    "                   post_string, \n",
    "                   \"-f\",\n",
    "                   fold_no]\n",
    "\n",
    "result = subprocess.check_output(subprocess_list, \n",
    "                                 stderr=subprocess.STDOUT, \n",
    "                                 universal_newlines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-03-08 07:04:28.736668: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX\n",
      "Using TensorFlow backend.\n",
      "/mnt/NFS.cltlabnas1vg0/users/raghavendra/Github_version/evaluate_CV_v2_FUSE_CNNwithAF.py:86: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n",
      "  test_model = Model(input=[input_a, input_a_AF], output=[out])\n",
      "arch file is /mnt/NFS.cltlabnas1vg0/users/raghavendra/Github_version/best_result/run_1model_SPOKEN_Siamese.yaml\n",
      "Model path is /mnt/NFS.cltlabnas1vg0/users/raghavendra/Github_version/best_result/run_1SPOKEN_Siamese_3.0_foldno_1_48-0.72.hdf5\n",
      "Tensor(\"model_1/concatenate_1/concat:0\", shape=(?, 6), dtype=float32) Tensor(\"model_1_1/concatenate_1/concat:0\", shape=(?, 6), dtype=float32)\n",
      "Original model is \n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input1 (InputLayer)              (None, 1000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input1_AF (InputLayer)           (None, 8, 1)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input2 (InputLayer)              (None, 1000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input2_AF (InputLayer)           (None, 8, 1)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 6)             12001806    input1[0][0]                     \n",
      "                                                                   input2[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "model_2 (Model)                  (None, 30)            3710        input1_AF[0][0]                  \n",
      "                                                                   input2_AF[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 36)            0           model_1[1][0]                    \n",
      "                                                                   model_2[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)      (None, 36)            0           model_1[2][0]                    \n",
      "                                                                   model_2[2][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2)             74          concatenate_2[0][0]              \n",
      "                                                                   concatenate_3[0][0]              \n",
      "____________________________________________________________________________________________________\n",
      "main_output_1 (Activation)       (None, 2)             0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "main_output_2 (Activation)       (None, 2)             0           dense_2[1][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "aux_output (Lambda)              (None, 1)             0           model_1[1][0]                    \n",
      "                                                                   model_1[2][0]                    \n",
      "====================================================================================================\n",
      "Total params: 12,005,590\n",
      "Trainable params: 12,005,590\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "Test model is \n",
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "input1 (InputLayer)              (None, 1000)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "input1_AF (InputLayer)           (None, 8, 1)          0                                            \n",
      "____________________________________________________________________________________________________\n",
      "model_1 (Model)                  (None, 6)             12001806    input1[0][0]                     \n",
      "____________________________________________________________________________________________________\n",
      "model_2 (Model)                  (None, 30)            3710        input1_AF[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)      (None, 36)            0           model_1[3][0]                    \n",
      "                                                                   model_2[3][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 2)             74          concatenate_2[1][0]              \n",
      "____________________________________________________________________________________________________\n",
      "main_output_1 (Activation)       (None, 2)             0           dense_2[2][0]                    \n",
      "====================================================================================================\n",
      "Total params: 12,005,590\n",
      "Trainable params: 12,005,590\n",
      "Non-trainable params: 0\n",
      "____________________________________________________________________________________________________\n",
      "None\n",
      "1\n",
      "Post_string is test\n",
      "no_steps are 1\n",
      "last batch\n",
      "Number of samples processed is 1\n",
      "Test Acc and f1-score are 100.0, 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "raghuTestCommand = '''\n",
    "CUDA_VISIBLE_DEVICES=\" \" %s %s %s %s %s %s %s %s %s %s -n %s -tr_dir %s -p %s -f %s \n",
    "''' % (python_path, \n",
    "       exec_path,\n",
    "       arch_file,\n",
    "       model_path, \n",
    "       data_dir, \n",
    "       out_dir, \n",
    "       weight, \n",
    "       suffix, \n",
    "       layer_indices, \n",
    "       AF_data_path, \n",
    "       new_transcripts, \n",
    "       transcripts_dir, \n",
    "       post_string, \n",
    "       fold_no)\n",
    "\n",
    "print(raghuTestCommand)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "result = os.system(raghuTestCommand)\n",
    "print(result)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "CUDA_VISIBLE_DEVICES=\" \" python ${src_dir}/evaluate_CV_v2_FUSE_CNNwithAF.py arch_file model_path data_dir  out_dir weight suffix layer_indices AF_data_path -n new_transcripts -tr_dir transcripts_dir -p post_string -f fold_no \n",
    "\n",
    "    Inputs description: \n",
    "        arch_file -- model architecture used for training\n",
    "        model_path -- model weights stored in training\n",
    "        data_dir -- Path for data dir which should contain tokenizer and utt2label_test.txt\n",
    "        out_dir -- dir to store the results file\n",
    "        weight -- Constant factor of verification loss, not used in any where except to store the result. Technically, can    \n",
    "                    be given any value at the time of evaluation.\n",
    "        suffix -- suffix need to be added to result file name. Again, can be given any string.\n",
    "        layer_indices -- list of layer indices of your model using which you will extract features. In the present case,\n",
    "                         anything can be given because I hard coded layer indices in the code.\n",
    "        AF_data_path -- path for h5 file which should contain temporal features\n",
    "        (-n)--new_transcripts -- boolean, set to 1 if you are using new transcripts, otherwise set to 0 (default)\n",
    "        (-tr_dir)--transcripts_dir -- path for transcripts\n",
    "        (-p)--post_string -- data set to be evaluated. Can take \"train\", \"test\"(default)\n",
    "        (-f)--fold_no -- Cross validation fold number. Tokenizer will be selected based on this, model_path and arch_file\n",
    "                        should also be correspong to this fold number\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
